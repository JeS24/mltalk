<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Weekly Talk</title>
    <link href="http://www.niser.ac.in/~smishra/css/smlab.css" rel="stylesheet" type="text/css" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
</head>

<body>
    <div class="container">
        
	<h1>Weekly Talk on ML</h1> <br><br> 
        Every Week @Subhankar Mishra's Lab, NISER<br><br>
        <hr/>

	<br>
	<h2>Upcoming Talk</h2> (Talk 6)
        <br><br>
        <b>Speaker</b>: Nalin Kumar <br><br>
	<b>Date/Time</b>: Saturday, Feb 27th, 2021| 7:00 PM <br><br>
	<b>Title</b>: TBA <br><br>	
	<b>Abstract</b>: TBA<br>
        <hr/>
        
	
	<br>
	<h2>Talk 5</h2> 
        <br><br>
        <b>Speaker</b>: Annada Prasad Behera <br><br>
	<b>Date/Time</b>: Monday, Feb 15th, 2021| 7:00 PM<br><br>
	<b>Title</b>: Synthesis of novel views by estimating radiance fields.<br><br>	
	<b>Abstract</b>: In this talk, I'll briefly discuss the following (a) the rendering integral (b) the radiance function and finally talk about a (c) method for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views.<br>
        <br>
	<b>Slides</b>: <br>
	    To be uploaded soon. <br> <br>
	<hr/>
	    
	    
	<br>
	<h2>Talk 4</h2> 
        <br><br>
        <b>Speaker</b>: Rucha Bhalchandra Joshi <br><br>
	<b>Date/Time</b>: Monday, Feb 8th, 2021| 7:00 PM <br><br>
	<b>Title</b>: Handling Missing Data with Graph Representation Learning <a href="https://proceedings.neurips.cc/paper/2020/file/dc36f18a9a0a776671d4879cae69b551-Paper.pdf">[Paper Link]</a><br><br>	
	<b>Abstract</b>: Machine learning with missing data has been approached in two different ways, including feature imputation where missing feature values are estimated based on observed values and label prediction where downstream labels are learned directly from incomplete data. However, existing imputation models tend to have strong prior assumptions and cannot learn from downstream tasks, while models targeting label prediction often involve heuristics and can encounter scalability issues. Here we propose GRAPE, a graph-based framework for feature imputation as well as label prediction. GRAPE tackles the missing data problem using a graph representation, where the observations and features are viewed as two types of nodes in a bipartite graph, and the observed feature values as edges. Under the GRAPE framework, the feature imputation is formulated as an edge-level prediction task and the label prediction as a node-level prediction task. These tasks are then solved with Graph Neural Networks. Experimental results on nine benchmark datasets show that GRAPE yields 20% lower mean absolute error for imputation tasks and 10% lower for label prediction tasks, compared with existing state-of-the-art methods. 
<br><br>
	<b>Slides</b>: <br>
	    <embed src="https://drive.google.com/file/d/1-N4ucn-whUEM0LN8VEhBJvBaRNHlhhJa/preview?usp=sharing" height="400" width="100%" /> <br> <br>
	<hr/>
	
	    
	<br>
	<h2>Talk 3</h2> 
        <br><br>
        <b>Speaker</b>: Aman Upadhyay<br><br>
	<b>Date/Time</b>: Friday, Jan 15th, 2021| 7:00 PM <br><br>
	<b>Title</b>: Why are the lottery tickets winning?<br><br>	
	<b>Abstract</b>: Neural networks are highly over parametrized and pruning such networks is a way to get faster inference and lower storage requirements for our networks. Winning lottery ticket is one such algorithm that prunes the network by finding the "important weights" in a network and retraining the network with these weights. We will briefly discuss the algorithm as proposed in paper 1 and 2 attached, and then try to find why it works (paper 3 and 4) and the shortcomings of the algorithm.  There is a proposed algorithm in the 4th paper I have attached which tries to overcome this weakness.<br>
        <br>
	<b>Slides</b>: <br>
	    To be uploaded soon. <br><br>
	<b>Reference Paper(s)</b>: <a href="https://arxiv.org/pdf/1803.03635.pdf"> Paper 1</a>,  <a href="https://arxiv.org/pdf/1903.01611.pdf"> Paper 2</a>,  <a href="https://papers.nips.cc/paper/2019/hash/1113d7a76ffceca1bb350bfe145467c6-Abstract.html"> Paper 3</a>,  <a href="https://arxiv.org/abs/2006.05467"> Paper 4</a>
	<hr/> 
	    
	<br>
	<h2>Talk 2</h2> 
        <br><br>
        <b>Speaker</b>: Jyotirmaya Shivottam <br><br>
	<b>Date/Time</b>: Friday, Jan 8th, 2021| 7:00 PM <br><br>
	<b>Title</b>: Near Real-Time Incremental Learning for Object Detection at the Edge <a href="https://arxiv.org/abs/1904.00781">[arXiv]</a><br><br>	
	<b>Abstract</b>: One of the most interesting areas for application of object detection techniques is Internet of Things (IoT) or in a nutshell, "Edge Computing devices". Most of current research is focussed on tuning and compressing networks that can be run with limited resources on such devices, but this usually takes hours of training time. As such, a crucial component for AI on the edge has to be real-time Incremental Learning (IL) of new object classes. In this talk, the paper I will be presenting, explores this avenue and combats the problem of Catastrophic Forgetting (CF), by introducing a novel one-stage deep object detection algorithm, that incorporates some insights from the Learning without Forgetting (LwF) Knowledge Distillation technique. Additionally, the authors have designed an automated training dataset construction pipeline for the new object class, that ensures that the inference capability of the edge device is near real-time.<br>
        <br>
	<b>Slides</b>: <br>
	    <embed src="https://drive.google.com/file/d/1C9CzBGYoOh4lLqm2wM3u_ZiYt2MIii5T/preview?usp=sharing" height="400" width="100%" /> <br> <br>
	
	<hr/>
	    
	    
	<br>
	<h2>Talk 1</h2> 
        <br><br>
        <b>Speaker</b>: Danush Shekar <br><br>
	<b>Date/Time</b>: Friday, Jan 1st, 2021| 7:00 PM <br><br>
	<b>Title</b>: Fooling automated surveillance cameras: adversarial patches to attack person detection <a href="https://arxiv.org/pdf/1904.08653.pdf">[arXiv]</a><br><br>	
	<b>Abstract</b>: We have all seen machine learning algorithms gaining widespread attention in multiple industries. Surveillance and security is one such area where machine learning has applications in. Recent research papers have been focussing on finding image patches for such algorithms which cause say, a classifier, to ignore the said object. The arXiv paper I will be presenting is one such example, wherein the authors present an approach to generate adversarial image patches that one can wear or hold to be hidden from a person-detection classifier. <br>
        <br>
	<b>Slides</b>: <br>
	    <embed src="https://drive.google.com/file/d/1JCfbtZFIOJS9y1xkcF2gm0TgWyzCVb0S/preview?usp=sharing" height="400" width="100%" /> <br> <br>
	<b>Reference Paper(s)</b>: <a href="https://arxiv.org/pdf/1708.06131.pdf"> Link </a>
	<hr/>
        
    </div>
</body>

</html>
